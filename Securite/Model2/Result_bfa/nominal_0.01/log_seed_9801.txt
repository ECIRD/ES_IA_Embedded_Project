save path : ./save/tinyvgg_quan/nominal_0.01
{'data_path': './dataset', 'arch': 'tinyvgg_quan', 'dataset': 'cifar10', 'epochs': 40, 'start_epoch': 0, 'attack_sample_size': 100, 'test_batch_size': 100, 'optimizer': 'SGD', 'schedule': [25, 40], 'gammas': [0.1, 0.1], 'workers': 4, 'ngpu': 0, 'gpu_id': 0, 'print_freq': 100, 'decay': 0.0003, 'momentum': 0.9, 'limit_layer': -1, 'randbet_coeff': 10, 'k_top': 100, 'randbet': False, 'clipping_coeff': 0.0, 'learning_rate': 0.01, 'manualSeed': 9801, 'save_path': './save/tinyvgg_quan/nominal_0.01', 'enable_bfa': False, 'resume': '', 'quan_bitwidth': None, 'reset_weight': False, 'evaluate': False, 'n_iter': 30, 'model_only': False, 'random_bfa': False, 'use_cuda': False}
Random Seed: 9801
python version : 3.12.12 | packaged by Anaconda, Inc. | (main, Oct 14 2025, 16:10:16) [MSC v.1929 64 bit (AMD64)]
torch  version : 2.5.1
cudnn  version : None
=> creating model 'tinyvgg_quan'
=> network :
 TinyVGG(
  (features): Sequential(
    (0): quan_Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): quan_Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): quan_Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): quan_Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): quan_Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): quan_Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): quan_Linear(in_features=256, out_features=10, bias=True)
  )
)
=> do not use any checkpoint for tinyvgg_quan model

==>>[2025-10-22 14:43:23] [Epoch=000/040] [Need: 00:00:00] [LR=0.0100] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/500]   Time 21.635 (21.635)   Data 21.303 (21.303)   Loss 2.3019 (2.3019)   Prec@1 6.000 (6.000)   Prec@5 53.000 (53.000)   [2025-10-22 14:43:44]
  Epoch: [000][100/500]   Time 0.089 (0.304)   Data 0.000 (0.211)   Loss 2.2947 (2.3020)   Prec@1 15.000 (10.604)   Prec@5 55.000 (51.010)   [2025-10-22 14:43:53]
  Epoch: [000][200/500]   Time 0.087 (0.197)   Data 0.000 (0.107)   Loss 2.2860 (2.2913)   Prec@1 11.000 (12.169)   Prec@5 60.000 (54.015)   [2025-10-22 14:44:02]
  Epoch: [000][300/500]   Time 0.090 (0.162)   Data 0.001 (0.071)   Loss 2.0733 (2.2445)   Prec@1 25.000 (14.920)   Prec@5 77.000 (59.432)   [2025-10-22 14:44:11]
  Epoch: [000][400/500]   Time 0.090 (0.144)   Data 0.001 (0.054)   Loss 1.9038 (2.1854)   Prec@1 28.000 (17.539)   Prec@5 80.000 (64.087)   [2025-10-22 14:44:20]
  **Train** Prec@1 20.232 Prec@5 68.000 Error@1 79.768
  **Test** Prec@1 35.820 Prec@5 86.480 Error@1 64.180
=> Obtain best accuracy, and update the best model

==>>[2025-10-22 14:44:54] [Epoch=001/040] [Need: 00:59:09] [LR=0.0100] [Best : Accuracy=35.82, Error=64.18]
  Epoch: [001][000/500]   Time 22.607 (22.607)   Data 22.396 (22.396)   Loss 1.9735 (1.9735)   Prec@1 34.000 (34.000)   Prec@5 81.000 (81.000)   [2025-10-22 14:45:16]
  Epoch: [001][100/500]   Time 0.644 (0.888)   Data 0.002 (0.224)   Loss 1.7157 (1.7584)   Prec@1 32.000 (33.980)   Prec@5 90.000 (86.931)   [2025-10-22 14:46:23]
  Epoch: [001][200/500]   Time 0.549 (0.772)   Data 0.002 (0.114)   Loss 1.6581 (1.7227)   Prec@1 33.000 (35.348)   Prec@5 90.000 (87.806)   [2025-10-22 14:47:29]
  Epoch: [001][300/500]   Time 0.654 (0.727)   Data 0.001 (0.077)   Loss 1.6709 (1.6909)   Prec@1 37.000 (36.811)   Prec@5 89.000 (88.425)   [2025-10-22 14:48:33]
