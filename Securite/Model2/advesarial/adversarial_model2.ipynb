{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyyH6_ZAkjSV"
      },
      "source": [
        "#Import lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60XALuvNkzoN",
        "outputId": "ba7f1add-a490-45f2-a8e1-f51b21acbb3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cleverhans\n",
            "  Downloading cleverhans-4.0.0-py3-none-any.whl.metadata (846 bytes)\n",
            "Collecting nose (from cleverhans)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pycodestyle (from cleverhans)\n",
            "  Downloading pycodestyle-2.14.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from cleverhans) (1.16.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from cleverhans) (3.10.0)\n",
            "Collecting mnist (from cleverhans)\n",
            "  Downloading mnist-0.2.2-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from cleverhans) (2.0.2)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.12/dist-packages (from cleverhans) (0.25.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from cleverhans) (1.5.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from cleverhans) (1.13)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from cleverhans) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from cleverhans) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->cleverhans) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->cleverhans) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->cleverhans) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->cleverhans) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->cleverhans) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->cleverhans) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->cleverhans) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->cleverhans) (2.9.0.post0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability->cleverhans) (3.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability->cleverhans) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.12/dist-packages (from tensorflow-probability->cleverhans) (0.1.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.12/dist-packages (from dm-tree->tensorflow-probability->cleverhans) (25.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from dm-tree->tensorflow-probability->cleverhans) (2.0.0)\n",
            "Downloading cleverhans-4.0.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycodestyle-2.14.0-py2.py3-none-any.whl (31 kB)\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-4.0.0 mnist-0.2.2 nose-1.3.7 pycodestyle-2.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install cleverhans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zNDxova5khmt"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from absl import app, flags\n",
        "from easydict import EasyDict\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Conv2D, Input\n",
        "\n",
        "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
        "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUGzn3myli9e"
      },
      "source": [
        "## LOAD CIFAR-10 DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Okn5fVGClfA0"
      },
      "outputs": [],
      "source": [
        "def ld_cifar10():\n",
        "    \"\"\"Load training and test data.\"\"\"\n",
        "\n",
        "    def convert_types(image, label):\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        image /= 127.5\n",
        "        image -= 1.0\n",
        "        return image, label\n",
        "\n",
        "    dataset, info = tfds.load(\"cifar10\", with_info=True, as_supervised=True)\n",
        "\n",
        "    def augment_mirror(x):\n",
        "        return tf.image.random_flip_left_right(x)\n",
        "\n",
        "    def augment_shift(x, w=4):\n",
        "        y = tf.pad(x, [[w] * 2, [w] * 2, [0] * 2], mode=\"REFLECT\")\n",
        "        return tf.image.random_crop(y, tf.shape(x))\n",
        "\n",
        "    cifar10_train, cifar10_test = dataset[\"train\"], dataset[\"test\"]\n",
        "    # Augmentation helps a lot in CIFAR10\n",
        "    cifar10_train = cifar10_train.map(\n",
        "        lambda x, y: (augment_mirror(augment_shift(x)), y)\n",
        "    )\n",
        "    cifar10_train = cifar10_train.map(convert_types).shuffle(10000).batch(128)\n",
        "    cifar10_test = cifar10_test.map(convert_types).batch(1000)\n",
        "\n",
        "    return EasyDict(train=cifar10_train, test=cifar10_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "rfPG7y4LlI_l",
        "outputId": "def4bab8-adb9-4acc-ee31-d0557517ae14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"VGG11_CIFAR10_simple\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"VGG11_CIFAR10_simple\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_16 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_17 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_18 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_19 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m20,490\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout2d_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,642\u001b[0m (193.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,642</span> (193.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49,386\u001b[0m (192.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,386</span> (192.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50000/50000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 446us/step - epoch: 0.0000e+00 - Loss (train): 1.8077\n",
            "\u001b[1m50000/50000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256us/step - epoch: 1.0000 - Loss (train): 1.5039\n",
            "\u001b[1m50000/50000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254us/step - epoch: 2.0000 - Loss (train): 1.3626\n",
            "\u001b[1m50000/50000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247us/step - epoch: 3.0000 - Loss (train): 1.2679\n",
            "\u001b[1m50000/50000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253us/step - epoch: 4.0000 - Loss (train): 1.1988\n",
            "\u001b[1m50000/50000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259us/step - epoch: 5.0000 - Loss (train): 1.1442\n",
            "\u001b[1m50000/50000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 267us/step - epoch: 6.0000 - Loss (train): 1.0997\n",
            "\u001b[1m50000/50000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247us/step - epoch: 7.0000 - Loss (train): 1.0629\n",
            "\u001b[1m50000/50000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252us/step - epoch: 8.0000 - Loss (train): 1.0313\n",
            "\u001b[1m31744/50000\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 310us/step - epoch: 9.0000 - Loss (train): 1.0085"
          ]
        }
      ],
      "source": [
        "# Variables\n",
        "nb_epochs=50\n",
        "#Les budgets sont en norme infini\n",
        "adv_perturbation_budget=0.3\n",
        "pgd_iterations=40\n",
        "pgd_step_budget=0.01\n",
        "\n",
        "adv_train=False #True pour faire la protection\n",
        "\n",
        "data = ld_cifar10()\n",
        "input_shape=(32,32,3)\n",
        "num_classes=10\n",
        "'''\n",
        "def step_decay(epoch):\n",
        "    initial_lr = 0.02\n",
        "    drop = 0.96\n",
        "    epochs_drop = 1\n",
        "    lr = initial_lr * (drop ** (epoch // epochs_drop))\n",
        "    return lr\n",
        "'''\n",
        "# Model Under Test\n",
        "\n",
        "def model0(input_shape = input_shape):\n",
        "    x=model = models.Sequential(name=\"VGG11_CIFAR10_simple\")\n",
        "    x=model.add(layers.Input(shape=input_shape))\n",
        "\n",
        "\n",
        "    x=model.add(layers.Conv2D(32, (3,3), padding='same', use_bias=True))\n",
        "    x=model.add(layers.Activation('relu'))\n",
        "    x=model.add(layers.BatchNormalization())\n",
        "\n",
        "    x=model.add(layers.Conv2D(32, (3,3), padding='same', use_bias=True))\n",
        "    x=model.add(layers.Activation('relu'))\n",
        "    x=model.add(layers.SpatialDropout2D(0.25))\n",
        "    x=model.add(layers.BatchNormalization())\n",
        "    x=model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "    x=model.add(layers.Conv2D(32, (3,3), padding='same', use_bias=True))\n",
        "    x=model.add(layers.Activation('relu'))\n",
        "    x=model.add(layers.BatchNormalization())\n",
        "\n",
        "    x=model.add(layers.Conv2D(32, (3,3), padding='same', use_bias=True))\n",
        "    x=model.add(layers.Activation('relu'))\n",
        "    x=model.add(layers.SpatialDropout2D(0.25))\n",
        "    x=model.add(layers.BatchNormalization())\n",
        "    x=model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "    x=model.add(layers.Flatten())\n",
        "    x=model.add(layers.Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "model = model0()\n",
        "# Load training and test data\n",
        "\n",
        "\n",
        "#model = Model(inputs, x)\n",
        "model.summary()\n",
        "\n",
        "loss_object = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "#lr_scheduler = tf.keras.callbacks.LearningRateScheduler(step_decay, verbose=0)\n",
        "\n",
        "# Metrics to track the different accuracies.\n",
        "train_loss = tf.metrics.Mean(name=\"train_loss\")\n",
        "train_acc_clean = tf.metrics.SparseCategoricalAccuracy()\n",
        "test_acc_clean = tf.metrics.SparseCategoricalAccuracy()\n",
        "test_acc_fgsm = tf.metrics.SparseCategoricalAccuracy()\n",
        "test_acc_pgd = tf.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(x)\n",
        "    loss = loss_object(y, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  train_acc_clean(y,predictions)\n",
        "\n",
        "# Train model with adversarial training\n",
        "for epoch in range(nb_epochs):\n",
        "  # keras like pp of progress\n",
        "  progress_bar_train = tf.keras.utils.Progbar(50000)\n",
        "  for (x, y) in data.train:\n",
        "    if adv_train:\n",
        "      # Replace clean example with adversarial example for adversarial training\n",
        "      x = projected_gradient_descent(model, x, adv_perturbation_budget, 0.01, 40, np.inf)\n",
        "    train_step(x, y)\n",
        "    progress_bar_train.add(x.shape[0], values=[(\"epoch\",epoch),(\"Loss (train)\", train_loss.result())])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtr4jBhgPCMv"
      },
      "outputs": [],
      "source": [
        "# Evaluate on clean and adversarial data\n",
        "progress_bar_test = tf.keras.utils.Progbar(10000)\n",
        "\n",
        "# Lists to store results for a few examples\n",
        "true_labels = []\n",
        "clean_preds = []\n",
        "fgsm_preds = []\n",
        "pgd_preds = []\n",
        "clean_confidences = []\n",
        "fgsm_confidences = []\n",
        "pgd_confidences = []\n",
        "\n",
        "sample_count = 0\n",
        "max_samples_to_display = 100  # Display results for up to 100 samples\n",
        "\n",
        "for x, y in data.test:\n",
        "  #print(np.shape(x))\n",
        "  y_pred = model(x)\n",
        "  test_acc_clean(y, y_pred)\n",
        "\n",
        "  #ATTACKS WITH FGSM\n",
        "  x_fgm = fast_gradient_method(model, x, adv_perturbation_budget, np.inf)\n",
        "  y_pred_fgm = model(x_fgm)\n",
        "  test_acc_fgsm(y, y_pred_fgm)\n",
        "\n",
        "  #ATTACKS WITH PGD (iterative attack)\n",
        "  x_pgd = projected_gradient_descent(model, x, adv_perturbation_budget, pgd_step_budget, pgd_iterations, np.inf)\n",
        "  y_pred_pgd = model(x_pgd)\n",
        "  test_acc_pgd(y, y_pred_pgd)\n",
        "\n",
        "  # Store results for display\n",
        "  if sample_count < max_samples_to_display:\n",
        "      true_labels.extend(tf.get_static_value(y[:max_samples_to_display-sample_count]))\n",
        "\n",
        "      clean_pred_values = tf.get_static_value(y_pred[:max_samples_to_display-sample_count])\n",
        "      clean_preds.extend(tf.get_static_value(tf.argmax(clean_pred_values, axis=1)))\n",
        "      clean_confidences.extend(tf.get_static_value(tf.reduce_max(tf.nn.softmax(clean_pred_values, axis=1), axis=1)))\n",
        "\n",
        "      fgsm_pred_values = tf.get_static_value(y_pred_fgm[:max_samples_to_display-sample_count])\n",
        "      fgsm_preds.extend(tf.get_static_value(tf.argmax(fgsm_pred_values, axis=1)))\n",
        "      fgsm_confidences.extend(tf.get_static_value(tf.reduce_max(tf.nn.softmax(fgsm_pred_values, axis=1), axis=1)))\n",
        "\n",
        "      pgd_pred_values = tf.get_static_value(y_pred_pgd[:max_samples_to_display-sample_count])\n",
        "      pgd_preds.extend(tf.get_static_value(tf.argmax(pgd_pred_values, axis=1)))\n",
        "      pgd_confidences.extend(tf.get_static_value(tf.reduce_max(tf.nn.softmax(pgd_pred_values, axis=1), axis=1)))\n",
        "\n",
        "\n",
        "      sample_count += x.shape[0]\n",
        "\n",
        "\n",
        "  #Print the clean accuracy (no attack) and the adversarial accuracy (i.e., the accuracy computed on the adversarial images)\n",
        "  #NB: CIFAR-10 has 10 labels, the \"random guess level\" is accuracy=1/10=0.1\n",
        "  progress_bar_test.add(x.shape[0])\n",
        "\n",
        "print(\"\\n--- Evaluation Results ---\")\n",
        "print(\"test acc on clean examples (%): {:.3f}\".format(test_acc_clean.result() * 100))\n",
        "print(\"test acc on FGM adversarial examples (%): {:.3f}\".format(test_acc_fgsm.result() * 100)) #Utilisation du gradient pour genere une images (un mask)\n",
        "print(\"test acc on PGD adversarial examples (%): {:.3f}\".format(test_acc_pgd.result() * 100)) #La meme mais en iterative\n",
        "\n",
        "# Display comparative table for a few examples\n",
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'True Label': true_labels,\n",
        "    'Clean Prediction': clean_preds,\n",
        "    'Clean Confidence': clean_confidences,\n",
        "    'FGSM Prediction': fgsm_preds,\n",
        "    'FGSM Confidence': fgsm_confidences,\n",
        "    'PGD Prediction': pgd_preds,\n",
        "    'PGD Confidence': pgd_confidences\n",
        "})\n",
        "\n",
        "print(\"\\n--- Comparative Table (First {} samples) ---\".format(max_samples_to_display))\n",
        "#display(results_df) # Commented out the display\n",
        "\n",
        "# Save the table to a text file\n",
        "adv_budget_str = str(adv_perturbation_budget).replace('.', '')\n",
        "pgd_step_str = str(pgd_step_budget).replace('.', '')\n",
        "if(adv_train==True):\n",
        "  filename = f'./sample_data/protected_resultat_model2_adv_{adv_budget_str}_pgdstep_{pgd_step_str}.txt'\n",
        "else:\n",
        "  filename = f'./sample_data/resultat_model2_adv_{adv_budget_str}_pgdstep_{pgd_step_str}.txt'\n",
        "\n",
        "with open(filename, 'w') as f:\n",
        "    f.write(\"--- Evaluation Results ---\\n\")\n",
        "    f.write(\"test acc on clean examples (%): {:.3f}\\n\".format(test_acc_clean.result() * 100))\n",
        "    f.write(\"test acc on FGM adversarial examples (%): {:.3f}\\n\".format(test_acc_fgsm.result() * 100))\n",
        "    f.write(\"test acc on PGD adversarial examples (%): {:.3f}\\n\".format(test_acc_pgd.result() * 100))\n",
        "    f.write(\"\\n--- Comparative Table (First {} samples) ---\\n\".format(max_samples_to_display))\n",
        "    results_df.to_csv(f, sep='\\t', index=False)\n",
        "\n",
        "print(f\"Comparative table saved to {filename}\")\n",
        "\n",
        "\n",
        "#SHOW THE ATTACK for a random sample\n",
        "rand_sample_id=np.random.randint(np.shape(x)[0])\n",
        "\n",
        "#We normalized our images into [0;1]. We make the inverse process to go into [0,255]\n",
        "#NB: For the attacked images, the max perturbation is +/-0.05, so the images will be in [-0.05,1.05]\n",
        "x_display = tf.cast(127.5*(x[rand_sample_id,:,:,:]+1.0),tf.uint8)\n",
        "x_pgd_display = tf.cast(121.4*(x_pgd[rand_sample_id,:,:,:]+1.05),tf.uint8)\n",
        "perturbation = x_pgd[rand_sample_id,:,:,:] - x[rand_sample_id,:,:,:]\n",
        "print('Maximum perturbation: ',np.amax(perturbation))\n",
        "\n",
        "#Display\n",
        "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(6, 2), subplot_kw={'xticks': [], 'yticks': []})\n",
        "axs.flat[0].imshow(tf.cast(x_display,tf.uint8))\n",
        "axs.flat[0].set_title(str('clean, label=')+str(tf.get_static_value(y[rand_sample_id])))\n",
        "axs.flat[1].imshow(tf.cast(x_pgd_display,tf.uint8))\n",
        "axs.flat[1].set_title(str('pgd, label=')+str(np.argmax(tf.get_static_value(y_pred_pgd[rand_sample_id]))))\n",
        "axs.flat[2].imshow(perturbation[:,:,0], cmap='gray')\n",
        "axs.flat[2].set_title('Perturbation Mask')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}