

Analyzing model 
C:/Users/hugoc/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/10.2.0/Utilities/windows/stedgeai.exe analyze --target stm32l4 --name mnist -m C:/Users/hugoc/OneDrive/Documents/Hugo/ISMIN/Cours/S9/E_IA/Projet/Github/ES_IA_Embedded_Project/Rapport_analyse/model_light/model_233k_80/model_light_233k_80.h5 --compression high --verbosity 1 --workspace C:/Users/hugoc/AppData/Local/Temp/mxAI_workspace1431932403570012624419825131979372 --output C:/Users/hugoc/.stm32cubemx/mnist_output 
ST Edge AI Core v2.2.0-20266 2adc00962 
Creating c (debug) info json file C:\Users\hugoc\.stm32cubemx\mnist_output\mnist_c_info.json 
  
 Exec/report summary (analyze) 
 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 
 model file         :   C:\Users\hugoc\OneDrive\Documents\Hugo\ISMIN\Cours\S9\E_IA\Projet\Github\ES_IA_Embedded_Project\Rapport_analyse\model_light\model_233k_80\model_light_233k_80.h5    
 type               :   keras                                                                                                                                                               
 c_name             :   mnist                                                                                                                                                               
 compression        :   high                                                                                                                                                                
 options            :   allocate-inputs, allocate-outputs                                                                                                                                   
 optimization       :   balanced                                                                                                                                                            
 target/series      :   stm32l4                                                                                                                                                             
 workspace dir      :   C:\Users\hugoc\AppData\Local\Temp\mxAI_workspace1431932403570012624419825131979372                                                                                  
 output dir         :   C:\Users\hugoc\.stm32cubemx\mnist_output                                                                                                                            
 model_fmt          :   float                                                                                                                                                               
 model_name         :   model_light_233k_80                                                                                                                                                 
 model_hash         :   0xcedd5ee451f10abe64b378ccff8938d9                                                                                                                                  
 params #           :   59,026 items (230.57 KiB)                                                                                                                                           
 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 
 input 1/1          :   'input_layer', f32(1x32x32x3), 12.00 KBytes, activations                                                                                                            
 output 1/1         :   'dense_1', f32(1x10), 40 Bytes, activations                                                                                                                         
 macc               :   8,427,720                                                                                                                                                           
 weights (ro)       :   201,896 B (197.16 KiB) (1 segment) / -34,208(-14.5%) vs float model                                                                                                 
 activations (rw)   :   70,400 B (68.75 KiB) (1 segment) *                                                                                                                                  
 ram (total)        :   70,400 B (68.75 KiB) = 70,400 + 0 + 0                                                                                                                               
 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 
 (*) 'input'/'output' buffers are allocated in the activations buffer 
Computing AI RT data/code size (target=stm32l4).. 
 Model name - model_light_233k_80 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 m_id   layer (original)                                         oshape                 param/size           macc                    connected to 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 0      input_layer (InputLayer)                                 [b:1,h:32,w:32,c:3] 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 1      conv2d (Conv2D)                                          [b:1,h:32,w:32,c:8]    216/864           221,184                     input_layer 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 2      batch_normalization (BatchNormalization)                 [b:1,h:32,w:32,c:8]    16/64              16,384                          conv2d 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 3      activation (Activation)                                  [b:1,h:32,w:32,c:8]                        8,192             batch_normalization 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 4      conv2d_1 (Conv2D)                                        [b:1,h:32,w:32,c:8]    576/2,304         589,824                      activation 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 5      batch_normalization_1 (BatchNormalization)               [b:1,h:32,w:32,c:8]    16/64              16,384                        conv2d_1 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 6      activation_1 (Activation)                                [b:1,h:32,w:32,c:8]                        8,192           batch_normalization_1 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 7      conv2d_2 (Conv2D)                                        [b:1,h:32,w:32,c:8]    576/2,304         589,824                    activation_1 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 8      batch_normalization_2 (BatchNormalization)               [b:1,h:32,w:32,c:8]    16/64              16,384                        conv2d_2 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 9      activation_2 (Activation)                                [b:1,h:32,w:32,c:8]                        8,192           batch_normalization_2 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 10     conv2d_3 (Conv2D)                                        [b:1,h:32,w:32,c:8]    576/2,304         589,824                    activation_2 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 11     batch_normalization_3 (BatchNormalization)               [b:1,h:32,w:32,c:8]    16/64              16,384                        conv2d_3 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 12     activation_3 (Activation)                                [b:1,h:32,w:32,c:8]                        8,192           batch_normalization_3 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 13     batch_normalization_4 (BatchNormalization)               [b:1,h:32,w:32,c:8]    16/64              16,384                    activation_3 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 14     add (Add)                                                [b:1,h:32,w:32,c:8]                        8,192           batch_normalization_4 
                                                                                                                                       activation 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 15     activation_4 (Activation)                                [b:1,h:32,w:32,c:8]                        8,192                             add 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 16     conv2d_4 (Conv2D)                                        [b:1,h:32,w:32,c:8]    576/2,304         589,824                    activation_4 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 17     batch_normalization_5 (BatchNormalization)               [b:1,h:32,w:32,c:8]    16/64              16,384                        conv2d_4 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 18     activation_5 (Activation)                                [b:1,h:32,w:32,c:8]                        8,192           batch_normalization_5 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 19     conv2d_5 (Conv2D)                                        [b:1,h:32,w:32,c:8]    576/2,304         589,824                    activation_5 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 20     batch_normalization_6 (BatchNormalization)               [b:1,h:32,w:32,c:8]    16/64              16,384                        conv2d_5 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 21     activation_6 (Activation)                                [b:1,h:32,w:32,c:8]                        8,192           batch_normalization_6 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 22     conv2d_6 (Conv2D)                                        [b:1,h:32,w:32,c:8]    576/2,304         589,824                    activation_6 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 23     batch_normalization_7 (BatchNormalization)               [b:1,h:32,w:32,c:8]    16/64              16,384                        conv2d_6 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 24     activation_7 (Activation)                                [b:1,h:32,w:32,c:8]                        8,192           batch_normalization_7 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 25     batch_normalization_8 (BatchNormalization)               [b:1,h:32,w:32,c:8]    16/64              16,384                    activation_7 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 26     add_1 (Add)                                              [b:1,h:32,w:32,c:8]                        8,192           batch_normalization_8 
                                                                                                                                     activation_4 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 27     activation_8 (Activation)                                [b:1,h:32,w:32,c:8]                        8,192                           add_1 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 28     max_pooling2d (MaxPooling2D)                             [b:1,h:16,w:16,c:8]                        8,192                    activation_8 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 30     conv2d_7 (Conv2D)                                        [b:1,h:16,w:16,c:16]   1,152/4,608       294,912                   max_pooling2d 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 31     batch_normalization_9 (BatchNormalization)               [b:1,h:16,w:16,c:16]   32/128              8,192                        conv2d_7 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 32     activation_9 (Activation)                                [b:1,h:16,w:16,c:16]                       4,096           batch_normalization_9 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 33     conv2d_8 (Conv2D)                                        [b:1,h:16,w:16,c:16]   2,304/9,216       589,824                    activation_9 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 34     batch_normalization_10 (BatchNormalization)              [b:1,h:16,w:16,c:16]   32/128              8,192                        conv2d_8 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 35     activation_10 (Activation)                               [b:1,h:16,w:16,c:16]                       4,096          batch_normalization_10 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 36     conv2d_9 (Conv2D)                                        [b:1,h:16,w:16,c:16]   2,304/9,216       589,824                   activation_10 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 37     batch_normalization_11 (BatchNormalization)              [b:1,h:16,w:16,c:16]   32/128              8,192                        conv2d_9 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 38     activation_11 (Activation)                               [b:1,h:16,w:16,c:16]                       4,096          batch_normalization_11 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 39     conv2d_10 (Conv2D)                                       [b:1,h:16,w:16,c:16]   128/512            32,768                   max_pooling2d 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 40     batch_normalization_13 (BatchNormalization)              [b:1,h:16,w:16,c:16]   32/128              8,192                   activation_11 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 41     batch_normalization_12 (BatchNormalization)              [b:1,h:16,w:16,c:16]   32/128              8,192                       conv2d_10 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 42     add_2 (Add)                                              [b:1,h:16,w:16,c:16]                       4,096          batch_normalization_13 
                                                                                                                           batch_normalization_12 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 43     activation_12 (Activation)                               [b:1,h:16,w:16,c:16]                       4,096                           add_2 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 44     conv2d_11 (Conv2D)                                       [b:1,h:16,w:16,c:16]   2,304/9,216       589,824                   activation_12 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 45     batch_normalization_14 (BatchNormalization)              [b:1,h:16,w:16,c:16]   32/128              8,192                       conv2d_11 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 46     activation_13 (Activation)                               [b:1,h:16,w:16,c:16]                       4,096          batch_normalization_14 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 47     conv2d_12 (Conv2D)                                       [b:1,h:16,w:16,c:16]   2,304/9,216       589,824                   activation_13 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 48     batch_normalization_15 (BatchNormalization)              [b:1,h:16,w:16,c:16]   32/128              8,192                       conv2d_12 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 49     activation_14 (Activation)                               [b:1,h:16,w:16,c:16]                       4,096          batch_normalization_15 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 50     conv2d_13 (Conv2D)                                       [b:1,h:16,w:16,c:16]   2,304/9,216       589,824                   activation_14 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 51     batch_normalization_16 (BatchNormalization)              [b:1,h:16,w:16,c:16]   32/128              8,192                       conv2d_13 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 52     activation_15 (Activation)                               [b:1,h:16,w:16,c:16]                       4,096          batch_normalization_16 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 53     batch_normalization_17 (BatchNormalization)              [b:1,h:16,w:16,c:16]   32/128              8,192                   activation_15 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 54     add_3 (Add)                                              [b:1,h:16,w:16,c:16]                       4,096          batch_normalization_17 
                                                                                                                                    activation_12 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 55     activation_16 (Activation)                               [b:1,h:16,w:16,c:16]                       4,096                           add_3 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 56     max_pooling2d_1 (MaxPooling2D)                           [b:1,h:8,w:8,c:16]                         4,096                   activation_16 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 58     conv2d_14 (Conv2D)                                       [b:1,h:8,w:8,c:32]     4,608/18,432      294,912                 max_pooling2d_1 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 59     batch_normalization_18 (BatchNormalization)              [b:1,h:8,w:8,c:32]     64/256              4,096                       conv2d_14 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 60     activation_17 (Activation)                               [b:1,h:8,w:8,c:32]                         2,048          batch_normalization_18 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 61     conv2d_15 (Conv2D)                                       [b:1,h:8,w:8,c:32]     9,216/36,864      589,824                   activation_17 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 62     batch_normalization_19 (BatchNormalization)              [b:1,h:8,w:8,c:32]     64/256              4,096                       conv2d_15 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 63     activation_18 (Activation)                               [b:1,h:8,w:8,c:32]                         2,048          batch_normalization_19 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 64     max_pooling2d_2 (MaxPooling2D)                           [b:1,h:4,w:4,c:32]                         2,048                   activation_18 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 66     conv2d_16 (Conv2D)                                       [b:1,h:4,w:4,c:64]     18,432/73,728     294,912                 max_pooling2d_2 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 67     batch_normalization_20 (BatchNormalization)              [b:1,h:4,w:4,c:64]     128/512             2,048                       conv2d_16 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 68     activation_19 (Activation)                               [b:1,h:4,w:4,c:64]                         1,024          batch_normalization_20 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 69     max_pooling2d_3 (MaxPooling2D)                           [b:1,h:2,w:2,c:64]                         1,024                   activation_19 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 71     global_average_pooling2d_pool (GlobalAveragePooling2D)   [b:1,h:1,w:1,c:64]                           256                 max_pooling2d_3 
        global_average_pooling2d (GlobalAveragePooling2D)        [b:1,c:64]                                         global_average_pooling2d_pool 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 72     dense_dense (Dense)                                      [b:1,c:128]            8,320/33,280        8,320        global_average_pooling2d 
        dense (Dense)                                            [b:1,c:128]                                  128                     dense_dense 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 74     dense_1_dense (Dense)                                    [b:1,c:10]             1,290/5,160         1,290                           dense 
        dense_1 (Dense)                                          [b:1,c:10]                                   150                   dense_1_dense 
 ------ -------------------------------------------------------- ---------------------- --------------- --------- ------------------------------- 
 model: macc=8,609,696 weights=236,104 activations=-- io=-- 
 Number of operations per c-layer 
 ------- ------ -------------------------------------- ----------- -------------- 
 c_id    m_id   name (type)                                    #op           type 
 ------- ------ -------------------------------------- ----------- -------------- 
 0       2      conv2d (Conv2D)                            221,192   smul_f32_f32 
 1       3      activation (Nonlinearity)                    8,192     op_f32_f32 
 2       5      conv2d_1 (Conv2D)                          589,832   smul_f32_f32 
 3       6      activation_1 (Nonlinearity)                  8,192     op_f32_f32 
 4       8      conv2d_2 (Conv2D)                          589,832   smul_f32_f32 
 5       9      activation_2 (Nonlinearity)                  8,192     op_f32_f32 
 6       11     conv2d_3 (Conv2D)                          589,832   smul_f32_f32 
 7       12     activation_3 (Nonlinearity)                  8,192     op_f32_f32 
 8       13     batch_normalization_4 (ScaleBias)           16,384   smul_f32_f32 
 9       14     add (Eltwise/add)                            8,192     op_f32_f32 
 10      15     activation_4 (Nonlinearity)                  8,192     op_f32_f32 
 11      17     conv2d_4 (Conv2D)                          589,832   smul_f32_f32 
 12      18     activation_5 (Nonlinearity)                  8,192     op_f32_f32 
 13      20     conv2d_5 (Conv2D)                          589,832   smul_f32_f32 
 14      21     activation_6 (Nonlinearity)                  8,192     op_f32_f32 
 15      23     conv2d_6 (Conv2D)                          589,832   smul_f32_f32 
 16      24     activation_7 (Nonlinearity)                  8,192     op_f32_f32 
 17      25     batch_normalization_8 (ScaleBias)           16,384   smul_f32_f32 
 18      26     add_1 (Eltwise/add)                          8,192     op_f32_f32 
 19      27     activation_8 (Nonlinearity)                  8,192     op_f32_f32 
 20      28     max_pooling2d (Pool)                         8,192   smul_f32_f32 
 21      41     conv2d_10 (Conv2D)                          32,784   smul_f32_f32 
 22      31     conv2d_7 (Conv2D)                          294,928   smul_f32_f32 
 23      32     activation_9 (Nonlinearity)                  4,096     op_f32_f32 
 24      34     conv2d_8 (Conv2D)                          589,840   smul_f32_f32 
 25      35     activation_10 (Nonlinearity)                 4,096     op_f32_f32 
 26      37     conv2d_9 (Conv2D)                          589,840   smul_f32_f32 
 27      38     activation_11 (Nonlinearity)                 4,096     op_f32_f32 
 28      40     batch_normalization_13 (ScaleBias)           8,192   smul_f32_f32 
 29      42     add_2 (Eltwise/add)                          4,096     op_f32_f32 
 30      43     activation_12 (Nonlinearity)                 4,096     op_f32_f32 
 31      45     conv2d_11 (Conv2D)                         589,840   smul_f32_f32 
 32      46     activation_13 (Nonlinearity)                 4,096     op_f32_f32 
 33      48     conv2d_12 (Conv2D)                         589,840   smul_f32_f32 
 34      49     activation_14 (Nonlinearity)                 4,096     op_f32_f32 
 35      51     conv2d_13 (Conv2D)                         589,840   smul_f32_f32 
 36      52     activation_15 (Nonlinearity)                 4,096     op_f32_f32 
 37      53     batch_normalization_17 (ScaleBias)           8,192   smul_f32_f32 
 38      54     add_3 (Eltwise/add)                          4,096     op_f32_f32 
 39      55     activation_16 (Nonlinearity)                 4,096     op_f32_f32 
 40      56     max_pooling2d_1 (Pool)                       4,096   smul_f32_f32 
 41      59     conv2d_14 (Conv2D)                         294,944   smul_f32_f32 
 42      60     activation_17 (Nonlinearity)                 2,048     op_f32_f32 
 43      64     conv2d_15 (Conv2D)                         593,952   smul_f32_f32 
 44      69     conv2d_16 (Conv2D)                         297,024   smul_f32_f32 
 45      71     global_average_pooling2d_pool (Pool)           256   smul_f32_f32 
 46      72     dense_dense (Dense)                          8,320    smul_f32_f4 
 47      72     dense (Nonlinearity)                           128     op_f32_f32 
 48      74     dense_1_dense (Dense)                        1,290    smul_f32_f4 
 49      74     dense_1 (Nonlinearity)                         150     op_f32_f32 
 ------- ------ -------------------------------------- ----------- -------------- 
 total                                                   8,427,720 
 Number of operation types 
 ---------------- ----------- ----------- 
 operation type             #           % 
 ---------------- ----------- ----------- 
 smul_f32_f32       8,284,712       98.3% 
 op_f32_f32           133,398        1.6% 
 smul_f32_f4            9,610        0.1% 
 Complexity report (model) 
 ------ ------------------------------- ------------------------- ------------------------- ---------- 
 m_id   name                            c_macc                    c_rom                     c_id 
 ------ ------------------------------- ------------------------- ------------------------- ---------- 
 2      batch_normalization             ||||||             2.6%   |                  0.4%   [0] 
 3      activation                      |                  0.1%   |                  0.0%   [1] 
 5      batch_normalization_1           |||||||||||||||    7.0%   |                  1.2%   [2] 
 6      activation_1                    |                  0.1%   |                  0.0%   [3] 
 8      batch_normalization_2           |||||||||||||||    7.0%   |                  1.2%   [4] 
 9      activation_2                    |                  0.1%   |                  0.0%   [5] 
 11     batch_normalization_3           |||||||||||||||    7.0%   |                  1.2%   [6] 
 12     activation_3                    |                  0.1%   |                  0.0%   [7] 
 13     batch_normalization_4           |                  0.2%   |                  0.0%   [8] 
 14     add                             |                  0.1%   |                  0.0%   [9] 
 15     activation_4                    |                  0.1%   |                  0.0%   [10] 
 17     batch_normalization_5           |||||||||||||||    7.0%   |                  1.2%   [11] 
 18     activation_5                    |                  0.1%   |                  0.0%   [12] 
 20     batch_normalization_6           |||||||||||||||    7.0%   |                  1.2%   [13] 
 21     activation_6                    |                  0.1%   |                  0.0%   [14] 
 23     batch_normalization_7           |||||||||||||||    7.0%   |                  1.2%   [15] 
 24     activation_7                    |                  0.1%   |                  0.0%   [16] 
 25     batch_normalization_8           |                  0.2%   |                  0.0%   [17] 
 26     add_1                           |                  0.1%   |                  0.0%   [18] 
 27     activation_8                    |                  0.1%   |                  0.0%   [19] 
 28     max_pooling2d                   |                  0.1%   |                  0.0%   [20] 
 31     batch_normalization_9           ||||||||           3.5%   |                  2.3%   [22] 
 32     activation_9                    |                  0.0%   |                  0.0%   [23] 
 34     batch_normalization_10          |||||||||||||||    7.0%   ||                 4.6%   [24] 
 35     activation_10                   |                  0.0%   |                  0.0%   [25] 
 37     batch_normalization_11          |||||||||||||||    7.0%   ||                 4.6%   [26] 
 38     activation_11                   |                  0.0%   |                  0.0%   [27] 
 40     batch_normalization_13          |                  0.1%   |                  0.1%   [28] 
 41     batch_normalization_12          |                  0.4%   |                  0.3%   [21] 
 42     add_2                           |                  0.0%   |                  0.0%   [29] 
 43     activation_12                   |                  0.0%   |                  0.0%   [30] 
 45     batch_normalization_14          |||||||||||||||    7.0%   ||                 4.6%   [31] 
 46     activation_13                   |                  0.0%   |                  0.0%   [32] 
 48     batch_normalization_15          |||||||||||||||    7.0%   ||                 4.6%   [33] 
 49     activation_14                   |                  0.0%   |                  0.0%   [34] 
 51     batch_normalization_16          |||||||||||||||    7.0%   ||                 4.6%   [35] 
 52     activation_15                   |                  0.0%   |                  0.0%   [36] 
 53     batch_normalization_17          |                  0.1%   |                  0.1%   [37] 
 54     add_3                           |                  0.0%   |                  0.0%   [38] 
 55     activation_16                   |                  0.0%   |                  0.0%   [39] 
 56     max_pooling2d_1                 |                  0.0%   |                  0.0%   [40] 
 59     batch_normalization_18          ||||||||           3.5%   ||||               9.2%   [41] 
 60     activation_17                   |                  0.0%   |                  0.0%   [42] 
 64     max_pooling2d_2                 ||||||||||||||||   7.0%   ||||||||          18.3%   [43] 
 69     max_pooling2d_3                 ||||||||           3.5%   ||||||||||||||||  36.6%   [44] 
 71     global_average_pooling2d_pool   |                  0.0%   |                  0.0%   [45] 
 72     dense_dense                     |                  0.1%   |                  2.3%   [46, 47] 
 74     dense_1_dense                   |                  0.0%   |                  0.4%   [48, 49] 
 ------ ------------------------------- ------------------------- ------------------------- ---------- 
 macc=8,427,720 weights=201,896 act=70,400 ram_io=0 
 Requested memory size by section - "stm32l4" target 
 ------------------------------ -------- --------- -------- -------- 
 module                             text    rodata     data      bss 
 ------------------------------ -------- --------- -------- -------- 
 NetworkRuntime1020_CM4_GCC.a     15,356         0        0        0 
 mnist.o                           2,268       400   14,832      448 
 mnist_data.o                         48        16       88        0 
 lib (toolchain)*                    614        24        0        0 
 ------------------------------ -------- --------- -------- -------- 
 RT total**                       18,286       440   14,920      448 
 ------------------------------ -------- --------- -------- -------- 
 weights                               0   201,896        0        0 
 activations                           0         0        0   70,400 
 io                                    0         0        0        0 
 ------------------------------ -------- --------- -------- -------- 
 TOTAL                            18,286   202,336   14,920   70,848 
 ------------------------------ -------- --------- -------- -------- 
 *  toolchain objects (libm/libgcc*) 
 ** RT AI runtime objects (kernels+infrastructure) 
  Summary - "stm32l4" target 
  --------------------------------------------------- 
               FLASH (ro)      %*   RAM (rw)       % 
  --------------------------------------------------- 
  RT total         33,646   14.3%     15,368   17.9% 
  --------------------------------------------------- 
  TOTAL           235,542             85,768 
  --------------------------------------------------- 
  *  rt/total 
Creating txt report file C:\Users\hugoc\.stm32cubemx\mnist_output\mnist_analyze_report.txt 
elapsed time (analyze): 430.751s 
Model file:      model_light_233k_80.h5 
Total Flash:     235542 B (230.02 KiB) 
    Weights:     201896 B (197.16 KiB) 
    Library:     33646 B (32.86 KiB) 
Total Ram:       85768 B (83.76 KiB) 
    Activations: 70400 B (68.75 KiB) 
    Library:     15368 B (15.01 KiB) 
    Input:       12288 B (12.00 KiB included in Activations) 
    Output:      40 B (included in Activations) 
Done 
Analyze complete on AI model