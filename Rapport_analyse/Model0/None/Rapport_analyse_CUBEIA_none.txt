

Analyzing model 
C:/Users/Tete/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/10.2.0/Utilities/windows/stedgeai.exe analyze --target stm32l4 --name cifar10 -m C:/Users/Tete/Documents/ISMIN/3A/Cours/Majeur_ES/Conception_Systeme/Embedded Neural Network on MCU/Projet EI23-20250916/Initial_model_dataset/Model_initial/CIFAR10_CNN.h5 --compression none --verbosity 1 --workspace C:/Users/Tete/AppData/Local/Temp/mxAI_workspace39810662629002702916692892193565 --output C:/Users/Tete/.stm32cubemx/cifar10_output 
ST Edge AI Core v2.2.0-20266 2adc00962 
Creating c (debug) info json file C:\Users\Tete\.stm32cubemx\cifar10_output\cifar10_c_info.json 
  
 Exec/report summary (analyze) 
 ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 
 model file         :   C:\Users\Tete\Documents\ISMIN\3A\Cours\Majeur_ES\Conception_Systeme\Embedded Neural Network on MCU\Projet EI23-20250916\Initial_model_dataset\Model_initial\CIFAR10_CNN.h5    
 type               :   keras                                                                                                                                                                         
 c_name             :   cifar10                                                                                                                                                                       
 compression        :   none                                                                                                                                                                          
 options            :   allocate-inputs, allocate-outputs                                                                                                                                             
 optimization       :   balanced                                                                                                                                                                      
 target/series      :   stm32l4                                                                                                                                                                       
 workspace dir      :   C:\Users\Tete\AppData\Local\Temp\mxAI_workspace39810662629002702916692892193565                                                                                               
 output dir         :   C:\Users\Tete\.stm32cubemx\cifar10_output                                                                                                                                     
 model_fmt          :   float                                                                                                                                                                         
 model_name         :   CIFAR10_CNN                                                                                                                                                                   
 model_hash         :   0xa678a80ac53e5bf1967e4890ffb56629                                                                                                                                            
 params #           :   1,343,146 items (5.12 MiB)                                                                                                                                                    
 ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 
 input 1/1          :   'input_0', f32(1x32x32x3), 12.00 KBytes, activations                                                                                                                          
 output 1/1         :   'dense_2', f32(1x10), 40 Bytes, activations                                                                                                                                   
 macc               :   32,997,984                                                                                                                                                                    
 weights (ro)       :   5,372,584 B (5.12 MiB) (1 segment)                                                                                                                                            
 activations (rw)   :   143,468 B (140.11 KiB) (1 segment) *                                                                                                                                          
 ram (total)        :   143,468 B (140.11 KiB) = 143,468 + 0 + 0                                                                                                                                      
 ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 
 (*) 'input'/'output' buffers are allocated in the activations buffer 
Computing AI RT data/code size (target=stm32l4).. 
 Model name - CIFAR10_CNN 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 m_id   layer (original)                             oshape                 param/size                 macc            connected to 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 0      input_0 (None)                               [b:1,h:32,w:32,c:3] 
        conv2d (Conv2D)                              [b:1,h:32,w:32,c:32]   896/3,584               884,768                 input_0 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 1      activation (Activation)                      [b:1,h:32,w:32,c:32]                            32,768                  conv2d 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 2      batch_normalization (BatchNormalization)     [b:1,h:32,w:32,c:32]   64/256                   65,536              activation 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 3      conv2d_1 (Conv2D)                            [b:1,h:32,w:32,c:32]   9,248/36,992          9,437,216     batch_normalization 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 4      activation_1 (Activation)                    [b:1,h:32,w:32,c:32]                            32,768                conv2d_1 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 6      batch_normalization_1 (BatchNormalization)   [b:1,h:32,w:32,c:32]   64/256                   65,536            activation_1 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 7      max_pooling2d (MaxPooling2D)                 [b:1,h:16,w:16,c:32]                            32,768   batch_normalization_1 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 8      conv2d_2 (Conv2D)                            [b:1,h:16,w:16,c:64]   18,496/73,984         4,718,656           max_pooling2d 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 9      activation_2 (Activation)                    [b:1,h:16,w:16,c:64]                            16,384                conv2d_2 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 10     batch_normalization_2 (BatchNormalization)   [b:1,h:16,w:16,c:64]   128/512                  32,768            activation_2 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 11     conv2d_3 (Conv2D)                            [b:1,h:16,w:16,c:64]   36,928/147,712        9,437,248   batch_normalization_2 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 12     activation_3 (Activation)                    [b:1,h:16,w:16,c:64]                            16,384                conv2d_3 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 14     batch_normalization_3 (BatchNormalization)   [b:1,h:16,w:16,c:64]   128/512                  32,768            activation_3 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 15     max_pooling2d_1 (MaxPooling2D)               [b:1,h:8,w:8,c:64]                              16,384   batch_normalization_3 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 16     conv2d_4 (Conv2D)                            [b:1,h:8,w:8,c:128]    73,856/295,424        4,718,720         max_pooling2d_1 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 17     activation_4 (Activation)                    [b:1,h:8,w:8,c:128]                              8,192                conv2d_4 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 19     batch_normalization_4 (BatchNormalization)   [b:1,h:8,w:8,c:128]    256/1,024                16,384            activation_4 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 20     max_pooling2d_2 (MaxPooling2D)               [b:1,h:4,w:4,c:128]                              8,192   batch_normalization_4 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 21     conv2d_5 (Conv2D)                            [b:1,h:4,w:4,c:128]    147,584/590,336       2,359,424         max_pooling2d_2 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 22     activation_5 (Activation)                    [b:1,h:4,w:4,c:128]                              2,048                conv2d_5 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 24     batch_normalization_5 (BatchNormalization)   [b:1,h:4,w:4,c:128]    256/1,024                 4,096            activation_5 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 25     max_pooling2d_3 (MaxPooling2D)               [b:1,h:2,w:2,c:128]                              2,048   batch_normalization_5 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 26     flatten (Flatten)                            [b:1,c:512]                                                    max_pooling2d_3 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 27     dense_dense (Dense)                          [b:1,c:1024]           525,312/2,101,248       525,312                 flatten 
        dense (Dense)                                [b:1,c:1024]                                     1,024             dense_dense 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 29     dense_1_dense (Dense)                        [b:1,c:512]            524,800/2,099,200       524,800                   dense 
        dense_1 (Dense)                              [b:1,c:512]                                        512           dense_1_dense 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 31     dense_2_dense (Dense)                        [b:1,c:10]             5,130/20,520              5,130                 dense_1 
        dense_2 (Dense)                              [b:1,c:10]                                         150           dense_2_dense 
 ------ -------------------------------------------- ---------------------- ------------------- ----------- ----------------------- 
 model: macc=32,997,984 weights=5,372,584 activations=-- io=-- 
 Number of operations per c-layer 
 ------- ------ ----------------------------------- ------------ -------------- 
 c_id    m_id   name (type)                                  #op           type 
 ------- ------ ----------------------------------- ------------ -------------- 
 0       0      conv2d (Conv2D)                          884,768   smul_f32_f32 
 1       1      activation (Nonlinearity)                 32,768     op_f32_f32 
 2       2      batch_normalization (ScaleBias)           65,536   smul_f32_f32 
 3       3      conv2d_1 (Conv2D)                      9,437,216   smul_f32_f32 
 4       4      activation_1 (Nonlinearity)               32,768     op_f32_f32 
 5       6      batch_normalization_1 (ScaleBias)         65,536   smul_f32_f32 
 6       7      max_pooling2d (Pool)                      32,768   smul_f32_f32 
 7       8      conv2d_2 (Conv2D)                      4,718,656   smul_f32_f32 
 8       9      activation_2 (Nonlinearity)               16,384     op_f32_f32 
 9       10     batch_normalization_2 (ScaleBias)         32,768   smul_f32_f32 
 10      11     conv2d_3 (Conv2D)                      9,437,248   smul_f32_f32 
 11      12     activation_3 (Nonlinearity)               16,384     op_f32_f32 
 12      14     batch_normalization_3 (ScaleBias)         32,768   smul_f32_f32 
 13      15     max_pooling2d_1 (Pool)                    16,384   smul_f32_f32 
 14      16     conv2d_4 (Conv2D)                      4,718,720   smul_f32_f32 
 15      17     activation_4 (Nonlinearity)                8,192     op_f32_f32 
 16      19     batch_normalization_4 (ScaleBias)         16,384   smul_f32_f32 
 17      20     max_pooling2d_2 (Pool)                     8,192   smul_f32_f32 
 18      21     conv2d_5 (Conv2D)                      2,359,424   smul_f32_f32 
 19      22     activation_5 (Nonlinearity)                2,048     op_f32_f32 
 20      24     batch_normalization_5 (ScaleBias)          4,096   smul_f32_f32 
 21      25     max_pooling2d_3 (Pool)                     2,048   smul_f32_f32 
 22      27     dense_dense (Dense)                      525,312   smul_f32_f32 
 23      27     dense (Nonlinearity)                       1,024     op_f32_f32 
 24      29     dense_1_dense (Dense)                    524,800   smul_f32_f32 
 25      29     dense_1 (Nonlinearity)                       512     op_f32_f32 
 26      31     dense_2_dense (Dense)                      5,130   smul_f32_f32 
 27      31     dense_2 (Nonlinearity)                       150     op_f32_f32 
 ------- ------ ----------------------------------- ------------ -------------- 
 total                                                32,997,984 
 Number of operation types 
 ---------------- ------------ ----------- 
 operation type              #           % 
 ---------------- ------------ ----------- 
 smul_f32_f32       32,887,754       99.7% 
 op_f32_f32            110,230        0.3% 
 Complexity report (model) 
 ------ ----------------------- ------------------------- ------------------------- ---------- 
 m_id   name                    c_macc                    c_rom                     c_id 
 ------ ----------------------- ------------------------- ------------------------- ---------- 
 0      input_0                 ||                 2.7%   |                  0.1%   [0] 
 1      activation              |                  0.1%   |                  0.0%   [1] 
 2      batch_normalization     |                  0.2%   |                  0.0%   [2] 
 3      conv2d_1                |||||||||||||||   28.6%   |                  0.7%   [3] 
 4      activation_1            |                  0.1%   |                  0.0%   [4] 
 6      batch_normalization_1   |                  0.2%   |                  0.0%   [5] 
 7      max_pooling2d           |                  0.1%   |                  0.0%   [6] 
 8      conv2d_2                ||||||||          14.3%   |                  1.4%   [7] 
 9      activation_2            |                  0.0%   |                  0.0%   [8] 
 10     batch_normalization_2   |                  0.1%   |                  0.0%   [9] 
 11     conv2d_3                ||||||||||||||||  28.6%   ||                 2.7%   [10] 
 12     activation_3            |                  0.0%   |                  0.0%   [11] 
 14     batch_normalization_3   |                  0.1%   |                  0.0%   [12] 
 15     max_pooling2d_1         |                  0.0%   |                  0.0%   [13] 
 16     conv2d_4                ||||||||          14.3%   |||                5.5%   [14] 
 17     activation_4            |                  0.0%   |                  0.0%   [15] 
 19     batch_normalization_4   |                  0.0%   |                  0.0%   [16] 
 20     max_pooling2d_2         |                  0.0%   |                  0.0%   [17] 
 21     conv2d_5                ||||               7.2%   |||||             11.0%   [18] 
 22     activation_5            |                  0.0%   |                  0.0%   [19] 
 24     batch_normalization_5   |                  0.0%   |                  0.0%   [20] 
 25     max_pooling2d_3         |                  0.0%   |                  0.0%   [21] 
 27     dense_dense             |                  1.6%   ||||||||||||||||  39.1%   [22, 23] 
 29     dense_1_dense           |                  1.6%   |||||||||||||||   39.1%   [24, 25] 
 31     dense_2_dense           |                  0.0%   |                  0.4%   [26, 27] 
 ------ ----------------------- ------------------------- ------------------------- ---------- 
 macc=32,997,984 weights=5,372,584 act=143,468 ram_io=0 
 Requested memory size by section - "stm32l4" target 
 ------------------------------ -------- ----------- ------- --------- 
 module                             text      rodata    data       bss 
 ------------------------------ -------- ----------- ------- --------- 
 NetworkRuntime1020_CM4_GCC.a      9,740           0       0         0 
 cifar10.o                         1,444         224   8,252       316 
 cifar10_data.o                       48          16      88         0 
 lib (toolchain)*                    614          24       0         0 
 ------------------------------ -------- ----------- ------- --------- 
 RT total**                       11,846         264   8,340       316 
 ------------------------------ -------- ----------- ------- --------- 
 weights                               0   5,372,584       0         0 
 activations                           0           0       0   143,468 
 io                                    0           0       0         0 
 ------------------------------ -------- ----------- ------- --------- 
 TOTAL                            11,846   5,372,848   8,340   143,784 
 ------------------------------ -------- ----------- ------- --------- 
 *  toolchain objects (libm/libgcc*) 
 ** RT AI runtime objects (kernels+infrastructure) 
  Summary - "stm32l4" target 
  ------------------------------------------------- 
               FLASH (ro)     %*   RAM (rw)      % 
  ------------------------------------------------- 
  RT total         20,450   0.4%      8,656   5.7% 
  ------------------------------------------------- 
  TOTAL         5,393,034           152,124 
  ------------------------------------------------- 
  *  rt/total 
Creating txt report file C:\Users\Tete\.stm32cubemx\cifar10_output\cifar10_analyze_report.txt 
elapsed time (analyze): 112.449s 
Model file:      CIFAR10_CNN.h5 
Total Flash:     5393034 B (5.14 MiB) 
    Weights:     5372584 B (5.12 MiB) 
    Library:     20450 B (19.97 KiB) 
Total Ram:       152124 B (148.56 KiB) 
    Activations: 143468 B (140.11 KiB) 
    Library:     8656 B (8.45 KiB) 
    Input:       12288 B (12.00 KiB included in Activations) 
    Output:      40 B (included in Activations) 
Done 
Analyze complete on AI model 
Required Ram or Flash size for cifar10 is bigger than available Ram or Flash