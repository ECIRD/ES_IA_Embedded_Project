

Analyzing model 
C:/Users/hugoc/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/10.2.0/Utilities/windows/stedgeai.exe analyze --target stm32l4 --name mnist -m C:/Users/hugoc/OneDrive/Documents/Hugo/ISMIN/Cours/S9/E_IA/Projet/Modeles/Model8/CIFAR10_32x4_64x3_128x2_256_d128_d10.h5 --compression none --verbosity 1 --workspace C:/Users/hugoc/AppData/Local/Temp/mxAI_workspace68533731400015641131300355292658 --output C:/Users/hugoc/.stm32cubemx/mnist_output 
ST Edge AI Core v2.2.0-20266 2adc00962 
Creating c (debug) info json file C:\Users\hugoc\.stm32cubemx\mnist_output\mnist_c_info.json 
  
 Exec/report summary (analyze) 
 -------------------------------------------------------------------------------------------------------------------------------------------------- 
 model file         :   C:\Users\hugoc\OneDrive\Documents\Hugo\ISMIN\Cours\S9\E_IA\Projet\Modeles\Model8\CIFAR10_32x4_64x3_128x2_256_d128_d10.h5    
 type               :   keras                                                                                                                       
 c_name             :   mnist                                                                                                                       
 compression        :   none                                                                                                                        
 options            :   allocate-inputs, allocate-outputs                                                                                           
 optimization       :   balanced                                                                                                                    
 target/series      :   stm32l4                                                                                                                     
 workspace dir      :   C:\Users\hugoc\AppData\Local\Temp\mxAI_workspace68533731400015641131300355292658                                            
 output dir         :   C:\Users\hugoc\.stm32cubemx\mnist_output                                                                                    
 model_fmt          :   float                                                                                                                       
 model_name         :   CIFAR10_32x4_64x3_128x2_256_d128_d10                                                                                        
 model_hash         :   0x51f024d1635923202f854e1d9ab511d0                                                                                          
 params #           :   904,240 items (3.45 MiB)                                                                                                    
 -------------------------------------------------------------------------------------------------------------------------------------------------- 
 input 1/1          :   'input_0', f32(1x32x32x3), 12.00 KBytes, activations                                                                        
 output 1/1         :   'dense_11', f32(1x10), 40 Bytes, activations                                                                                
 macc               :   72,604,896                                                                                                                  
 weights (ro)       :   3,616,960 B (3.45 MiB) (1 segment)                                                                                          
 activations (rw)   :   156,800 B (153.12 KiB) (1 segment) *                                                                                        
 ram (total)        :   156,800 B (153.12 KiB) = 156,800 + 0 + 0                                                                                    
 -------------------------------------------------------------------------------------------------------------------------------------------------- 
 (*) 'input'/'output' buffers are allocated in the activations buffer 
Computing AI RT data/code size (target=stm32l4).. 
 Model name - CIFAR10_32x4_64x3_128x2_256_d128_d10 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 m_id   layer (original)                              oshape                 param/size                 macc             connected to 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 0      input_0 (None)                                [b:1,h:32,w:32,c:3] 
        activation_55 (Activation)                    [b:1,h:32,w:32,c:3]                              3,072                  input_0 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 1      batch_normalization_55 (BatchNormalization)   [b:1,h:32,w:32,c:3]    6/24                      6,144            activation_55 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 2      conv2d_50 (Conv2D)                            [b:1,h:32,w:32,c:32]   896/3,584               884,768   batch_normalization_55 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 3      activation_56 (Activation)                    [b:1,h:32,w:32,c:32]                            32,768                conv2d_50 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 4      batch_normalization_56 (BatchNormalization)   [b:1,h:32,w:32,c:32]   64/256                   65,536            activation_56 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 5      conv2d_51 (Conv2D)                            [b:1,h:32,w:32,c:32]   9,248/36,992          9,437,216   batch_normalization_56 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 6      activation_57 (Activation)                    [b:1,h:32,w:32,c:32]                            32,768                conv2d_51 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 7      batch_normalization_57 (BatchNormalization)   [b:1,h:32,w:32,c:32]   64/256                   65,536            activation_57 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 8      conv2d_52 (Conv2D)                            [b:1,h:32,w:32,c:32]   9,248/36,992          9,437,216   batch_normalization_57 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 9      activation_58 (Activation)                    [b:1,h:32,w:32,c:32]                            32,768                conv2d_52 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 10     batch_normalization_58 (BatchNormalization)   [b:1,h:32,w:32,c:32]   64/256                   65,536            activation_58 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 11     conv2d_53 (Conv2D)                            [b:1,h:32,w:32,c:32]   9,248/36,992          9,437,216   batch_normalization_58 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 12     activation_59 (Activation)                    [b:1,h:32,w:32,c:32]                            32,768                conv2d_53 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 13     batch_normalization_59 (BatchNormalization)   [b:1,h:32,w:32,c:32]   64/256                   65,536            activation_59 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 14     max_pooling2d_20 (MaxPooling2D)               [b:1,h:16,w:16,c:32]                            32,768   batch_normalization_59 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 16     conv2d_54 (Conv2D)                            [b:1,h:16,w:16,c:64]   18,496/73,984         4,718,656         max_pooling2d_20 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 17     activation_60 (Activation)                    [b:1,h:16,w:16,c:64]                            16,384                conv2d_54 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 18     batch_normalization_60 (BatchNormalization)   [b:1,h:16,w:16,c:64]   128/512                  32,768            activation_60 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 19     conv2d_55 (Conv2D)                            [b:1,h:16,w:16,c:64]   36,928/147,712        9,437,248   batch_normalization_60 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 20     activation_61 (Activation)                    [b:1,h:16,w:16,c:64]                            16,384                conv2d_55 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 21     batch_normalization_61 (BatchNormalization)   [b:1,h:16,w:16,c:64]   128/512                  32,768            activation_61 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 22     conv2d_56 (Conv2D)                            [b:1,h:16,w:16,c:64]   36,928/147,712        9,437,248   batch_normalization_61 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 23     activation_62 (Activation)                    [b:1,h:16,w:16,c:64]                            16,384                conv2d_56 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 24     batch_normalization_62 (BatchNormalization)   [b:1,h:16,w:16,c:64]   128/512                  32,768            activation_62 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 25     max_pooling2d_21 (MaxPooling2D)               [b:1,h:8,w:8,c:64]                              16,384   batch_normalization_62 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 27     conv2d_57 (Conv2D)                            [b:1,h:8,w:8,c:128]    73,856/295,424        4,718,720         max_pooling2d_21 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 28     activation_63 (Activation)                    [b:1,h:8,w:8,c:128]                              8,192                conv2d_57 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 29     batch_normalization_63 (BatchNormalization)   [b:1,h:8,w:8,c:128]    256/1,024                16,384            activation_63 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 30     conv2d_58 (Conv2D)                            [b:1,h:8,w:8,c:128]    147,584/590,336       9,437,312   batch_normalization_63 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 31     activation_64 (Activation)                    [b:1,h:8,w:8,c:128]                              8,192                conv2d_58 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 32     batch_normalization_64 (BatchNormalization)   [b:1,h:8,w:8,c:128]    256/1,024                16,384            activation_64 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 33     max_pooling2d_22 (MaxPooling2D)               [b:1,h:4,w:4,c:128]                              8,192   batch_normalization_64 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 35     conv2d_59 (Conv2D)                            [b:1,h:4,w:4,c:256]    295,168/1,180,672     4,718,848         max_pooling2d_22 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 36     activation_65 (Activation)                    [b:1,h:4,w:4,c:256]                              4,096                conv2d_59 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 37     batch_normalization_65 (BatchNormalization)   [b:1,h:4,w:4,c:256]    512/2,048                 8,192            activation_65 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 38     max_pooling2d_23 (MaxPooling2D)               [b:1,h:2,w:2,c:256]                              4,096   batch_normalization_65 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 40     flatten_5 (Flatten)                           [b:1,c:1024]                                                   max_pooling2d_23 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 41     dense_10_dense (Dense)                        [b:1,c:256]            262,400/1,049,600       262,400                flatten_5 
        dense_10 (Dense)                              [b:1,c:256]                                      2,560           dense_10_dense 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 43     dense_11_dense (Dense)                        [b:1,c:10]             2,570/10,280              2,570                 dense_10 
        dense_11 (Dense)                              [b:1,c:10]                                         150           dense_11_dense 
 ------ --------------------------------------------- ---------------------- ------------------- ----------- ------------------------ 
 model: macc=72,604,896 weights=3,616,960 activations=-- io=-- 
 Number of operations per c-layer 
 ------- ------ ------------------------------------ ------------ -------------- 
 c_id    m_id   name (type)                                   #op           type 
 ------- ------ ------------------------------------ ------------ -------------- 
 0       0      activation_55 (Nonlinearity)                3,072     op_f32_f32 
 1       1      batch_normalization_55 (ScaleBias)          6,144   smul_f32_f32 
 2       2      conv2d_50 (Conv2D)                        884,768   smul_f32_f32 
 3       3      activation_56 (Nonlinearity)               32,768     op_f32_f32 
 4       4      batch_normalization_56 (ScaleBias)         65,536   smul_f32_f32 
 5       5      conv2d_51 (Conv2D)                      9,437,216   smul_f32_f32 
 6       6      activation_57 (Nonlinearity)               32,768     op_f32_f32 
 7       7      batch_normalization_57 (ScaleBias)         65,536   smul_f32_f32 
 8       8      conv2d_52 (Conv2D)                      9,437,216   smul_f32_f32 
 9       9      activation_58 (Nonlinearity)               32,768     op_f32_f32 
 10      10     batch_normalization_58 (ScaleBias)         65,536   smul_f32_f32 
 11      11     conv2d_53 (Conv2D)                      9,437,216   smul_f32_f32 
 12      12     activation_59 (Nonlinearity)               32,768     op_f32_f32 
 13      13     batch_normalization_59 (ScaleBias)         65,536   smul_f32_f32 
 14      14     max_pooling2d_20 (Pool)                    32,768   smul_f32_f32 
 15      16     conv2d_54 (Conv2D)                      4,718,656   smul_f32_f32 
 16      17     activation_60 (Nonlinearity)               16,384     op_f32_f32 
 17      18     batch_normalization_60 (ScaleBias)         32,768   smul_f32_f32 
 18      19     conv2d_55 (Conv2D)                      9,437,248   smul_f32_f32 
 19      20     activation_61 (Nonlinearity)               16,384     op_f32_f32 
 20      21     batch_normalization_61 (ScaleBias)         32,768   smul_f32_f32 
 21      22     conv2d_56 (Conv2D)                      9,437,248   smul_f32_f32 
 22      23     activation_62 (Nonlinearity)               16,384     op_f32_f32 
 23      24     batch_normalization_62 (ScaleBias)         32,768   smul_f32_f32 
 24      25     max_pooling2d_21 (Pool)                    16,384   smul_f32_f32 
 25      27     conv2d_57 (Conv2D)                      4,718,720   smul_f32_f32 
 26      28     activation_63 (Nonlinearity)                8,192     op_f32_f32 
 27      29     batch_normalization_63 (ScaleBias)         16,384   smul_f32_f32 
 28      30     conv2d_58 (Conv2D)                      9,437,312   smul_f32_f32 
 29      31     activation_64 (Nonlinearity)                8,192     op_f32_f32 
 30      32     batch_normalization_64 (ScaleBias)         16,384   smul_f32_f32 
 31      33     max_pooling2d_22 (Pool)                     8,192   smul_f32_f32 
 32      35     conv2d_59 (Conv2D)                      4,718,848   smul_f32_f32 
 33      36     activation_65 (Nonlinearity)                4,096     op_f32_f32 
 34      37     batch_normalization_65 (ScaleBias)          8,192   smul_f32_f32 
 35      38     max_pooling2d_23 (Pool)                     4,096   smul_f32_f32 
 36      41     dense_10_dense (Dense)                    262,400   smul_f32_f32 
 37      41     dense_10 (Nonlinearity)                     2,560     op_f32_f32 
 38      43     dense_11_dense (Dense)                      2,570   smul_f32_f32 
 39      43     dense_11 (Nonlinearity)                       150     op_f32_f32 
 ------- ------ ------------------------------------ ------------ -------------- 
 total                                                 72,604,896 
 Number of operation types 
 ---------------- ------------ ----------- 
 operation type              #           % 
 ---------------- ------------ ----------- 
 op_f32_f32            206,486        0.3% 
 smul_f32_f32       72,398,410       99.7% 
 Complexity report (model) 
 ------ ------------------------ ------------------------- ------------------------- ---------- 
 m_id   name                     c_macc                    c_rom                     c_id 
 ------ ------------------------ ------------------------- ------------------------- ---------- 
 0      input_0                  |                  0.0%   |                  0.0%   [0] 
 1      batch_normalization_55   |                  0.0%   |                  0.0%   [1] 
 2      conv2d_50                ||                 1.2%   |                  0.1%   [2] 
 3      activation_56            |                  0.0%   |                  0.0%   [3] 
 4      batch_normalization_56   |                  0.1%   |                  0.0%   [4] 
 5      conv2d_51                |||||||||||||||   13.0%   |                  1.0%   [5] 
 6      activation_57            |                  0.0%   |                  0.0%   [6] 
 7      batch_normalization_57   |                  0.1%   |                  0.0%   [7] 
 8      conv2d_52                |||||||||||||||   13.0%   |                  1.0%   [8] 
 9      activation_58            |                  0.0%   |                  0.0%   [9] 
 10     batch_normalization_58   |                  0.1%   |                  0.0%   [10] 
 11     conv2d_53                |||||||||||||||   13.0%   |                  1.0%   [11] 
 12     activation_59            |                  0.0%   |                  0.0%   [12] 
 13     batch_normalization_59   |                  0.1%   |                  0.0%   [13] 
 14     max_pooling2d_20         |                  0.0%   |                  0.0%   [14] 
 16     conv2d_54                ||||||||           6.5%   |                  2.0%   [15] 
 17     activation_60            |                  0.0%   |                  0.0%   [16] 
 18     batch_normalization_60   |                  0.0%   |                  0.0%   [17] 
 19     conv2d_55                |||||||||||||||   13.0%   ||                 4.1%   [18] 
 20     activation_61            |                  0.0%   |                  0.0%   [19] 
 21     batch_normalization_61   |                  0.0%   |                  0.0%   [20] 
 22     conv2d_56                |||||||||||||||   13.0%   ||                 4.1%   [21] 
 23     activation_62            |                  0.0%   |                  0.0%   [22] 
 24     batch_normalization_62   |                  0.0%   |                  0.0%   [23] 
 25     max_pooling2d_21         |                  0.0%   |                  0.0%   [24] 
 27     conv2d_57                ||||||||           6.5%   ||||               8.2%   [25] 
 28     activation_63            |                  0.0%   |                  0.0%   [26] 
 29     batch_normalization_63   |                  0.0%   |                  0.0%   [27] 
 30     conv2d_58                ||||||||||||||||  13.0%   ||||||||          16.3%   [28] 
 31     activation_64            |                  0.0%   |                  0.0%   [29] 
 32     batch_normalization_64   |                  0.0%   |                  0.0%   [30] 
 33     max_pooling2d_22         |                  0.0%   |                  0.0%   [31] 
 35     conv2d_59                ||||||||           6.5%   ||||||||||||||||  32.6%   [32] 
 36     activation_65            |                  0.0%   |                  0.0%   [33] 
 37     batch_normalization_65   |                  0.0%   |                  0.1%   [34] 
 38     max_pooling2d_23         |                  0.0%   |                  0.0%   [35] 
 41     dense_10_dense           |                  0.4%   ||||||||||||||    29.0%   [36, 37] 
 43     dense_11_dense           |                  0.0%   |                  0.3%   [38, 39] 
 ------ ------------------------ ------------------------- ------------------------- ---------- 
 macc=72,604,896 weights=3,616,960 act=156,800 ram_io=0 
 Requested memory size by section - "stm32l4" target 
 ------------------------------ -------- ----------- -------- --------- 
 module                             text      rodata     data       bss 
 ------------------------------ -------- ----------- -------- --------- 
 NetworkRuntime1020_CM4_GCC.a      9,888           0        0         0 
 mnist.o                           2,048         320   12,044       364 
 mnist_data.o                         48          16       88         0 
 lib (toolchain)*                    614          24        0         0 
 ------------------------------ -------- ----------- -------- --------- 
 RT total**                       12,598         360   12,132       364 
 ------------------------------ -------- ----------- -------- --------- 
 weights                               0   3,616,960        0         0 
 activations                           0           0        0   156,800 
 io                                    0           0        0         0 
 ------------------------------ -------- ----------- -------- --------- 
 TOTAL                            12,598   3,617,320   12,132   157,164 
 ------------------------------ -------- ----------- -------- --------- 
 *  toolchain objects (libm/libgcc*) 
 ** RT AI runtime objects (kernels+infrastructure) 
  Summary - "stm32l4" target 
  ------------------------------------------------- 
               FLASH (ro)     %*   RAM (rw)      % 
  ------------------------------------------------- 
  RT total         25,090   0.7%     12,496   7.4% 
  ------------------------------------------------- 
  TOTAL         3,642,050           169,296 
  ------------------------------------------------- 
  *  rt/total 
Creating txt report file C:\Users\hugoc\.stm32cubemx\mnist_output\mnist_analyze_report.txt 
elapsed time (analyze): 58.219s 
Model file:      CIFAR10_32x4_64x3_128x2_256_d128_d10.h5 
Total Flash:     3642050 B (3.47 MiB) 
    Weights:     3616960 B (3.45 MiB) 
    Library:     25090 B (24.50 KiB) 
Total Ram:       169296 B (165.33 KiB) 
    Activations: 156800 B (153.12 KiB) 
    Library:     12496 B (12.20 KiB) 
    Input:       12288 B (12.00 KiB included in Activations) 
    Output:      40 B (included in Activations) 
Done 
Analyze complete on AI model 
Required Ram or Flash size for mnist is bigger than available Ram or Flash